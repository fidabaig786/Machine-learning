{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db85f38e",
   "metadata": {},
   "source": [
    "# Importing the required Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "17f07001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "69c7f0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from .mat file using scipy.io module\n",
    "data_dict = scipy.io.loadmat('WLDataCW.mat')\n",
    "\n",
    "# Extract data and label from the dictionary loaded above\n",
    "data = data_dict['data']\n",
    "label = data_dict['label']\n",
    "\n",
    "# Reshape data into a 2D array (360 rows x 31,744 columns) and convert it to a pandas DataFrame with column names\n",
    "data_df = pd.DataFrame(data.reshape(62*512, 360).T, columns=[f'feature_{i}' for i in range(62*512)])\n",
    "\n",
    "# Reshape label into a 1D array (360 elements) and convert it to a pandas DataFrame with a single column named 'label'\n",
    "label_df = pd.DataFrame(label.reshape(360,), columns=['label'])\n",
    "\n",
    "# Concatenate data and label DataFrames along columns axis (axis=1) to create the final DataFrame\n",
    "df = pd.concat([data_df, label_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "03134622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_31735</th>\n",
       "      <th>feature_31736</th>\n",
       "      <th>feature_31737</th>\n",
       "      <th>feature_31738</th>\n",
       "      <th>feature_31739</th>\n",
       "      <th>feature_31740</th>\n",
       "      <th>feature_31741</th>\n",
       "      <th>feature_31742</th>\n",
       "      <th>feature_31743</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.645161</td>\n",
       "      <td>1.577007</td>\n",
       "      <td>-2.884674</td>\n",
       "      <td>-7.294243</td>\n",
       "      <td>-8.769628</td>\n",
       "      <td>-6.107172</td>\n",
       "      <td>-0.875113</td>\n",
       "      <td>3.444995</td>\n",
       "      <td>3.762372</td>\n",
       "      <td>-0.507442</td>\n",
       "      <td>...</td>\n",
       "      <td>14.552163</td>\n",
       "      <td>21.187590</td>\n",
       "      <td>25.256897</td>\n",
       "      <td>22.113747</td>\n",
       "      <td>13.521024</td>\n",
       "      <td>6.434617</td>\n",
       "      <td>6.510839</td>\n",
       "      <td>12.609276</td>\n",
       "      <td>17.854654</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.225078</td>\n",
       "      <td>2.687866</td>\n",
       "      <td>3.478920</td>\n",
       "      <td>-0.998662</td>\n",
       "      <td>-7.863265</td>\n",
       "      <td>-11.353711</td>\n",
       "      <td>-7.627178</td>\n",
       "      <td>2.002784</td>\n",
       "      <td>12.165368</td>\n",
       "      <td>17.727137</td>\n",
       "      <td>...</td>\n",
       "      <td>6.335400</td>\n",
       "      <td>12.920719</td>\n",
       "      <td>12.482493</td>\n",
       "      <td>4.597783</td>\n",
       "      <td>-7.552145</td>\n",
       "      <td>-19.150581</td>\n",
       "      <td>-26.119247</td>\n",
       "      <td>-26.754780</td>\n",
       "      <td>-22.282345</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.414157</td>\n",
       "      <td>2.379914</td>\n",
       "      <td>-3.338521</td>\n",
       "      <td>-7.477322</td>\n",
       "      <td>-9.546935</td>\n",
       "      <td>-9.531569</td>\n",
       "      <td>-7.968606</td>\n",
       "      <td>-6.104305</td>\n",
       "      <td>-5.469647</td>\n",
       "      <td>-6.837555</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.434300</td>\n",
       "      <td>-7.721217</td>\n",
       "      <td>2.970876</td>\n",
       "      <td>9.848282</td>\n",
       "      <td>6.062175</td>\n",
       "      <td>-6.689582</td>\n",
       "      <td>-18.814631</td>\n",
       "      <td>-20.730404</td>\n",
       "      <td>-11.228072</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.311837</td>\n",
       "      <td>2.850084</td>\n",
       "      <td>1.313545</td>\n",
       "      <td>0.674265</td>\n",
       "      <td>1.052333</td>\n",
       "      <td>0.343137</td>\n",
       "      <td>-3.497101</td>\n",
       "      <td>-9.780030</td>\n",
       "      <td>-14.930172</td>\n",
       "      <td>-15.362961</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.649138</td>\n",
       "      <td>-3.250118</td>\n",
       "      <td>4.343658</td>\n",
       "      <td>10.612925</td>\n",
       "      <td>10.251337</td>\n",
       "      <td>2.091847</td>\n",
       "      <td>-8.952351</td>\n",
       "      <td>-15.475546</td>\n",
       "      <td>-13.764502</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9.322539</td>\n",
       "      <td>-2.384815</td>\n",
       "      <td>3.101957</td>\n",
       "      <td>4.720293</td>\n",
       "      <td>3.202580</td>\n",
       "      <td>2.139584</td>\n",
       "      <td>4.917171</td>\n",
       "      <td>11.307302</td>\n",
       "      <td>16.890072</td>\n",
       "      <td>16.279924</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.844177</td>\n",
       "      <td>-21.338095</td>\n",
       "      <td>-21.321344</td>\n",
       "      <td>-19.264174</td>\n",
       "      <td>-17.024244</td>\n",
       "      <td>-14.048934</td>\n",
       "      <td>-8.670050</td>\n",
       "      <td>-1.055577</td>\n",
       "      <td>5.491176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>-10.650115</td>\n",
       "      <td>-9.326292</td>\n",
       "      <td>-9.187932</td>\n",
       "      <td>-9.651434</td>\n",
       "      <td>-9.201318</td>\n",
       "      <td>-6.872770</td>\n",
       "      <td>-3.324494</td>\n",
       "      <td>-0.485164</td>\n",
       "      <td>-0.027376</td>\n",
       "      <td>-1.959681</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.496918</td>\n",
       "      <td>-7.160340</td>\n",
       "      <td>-5.629473</td>\n",
       "      <td>-3.690045</td>\n",
       "      <td>-1.307681</td>\n",
       "      <td>1.285857</td>\n",
       "      <td>3.856766</td>\n",
       "      <td>6.362743</td>\n",
       "      <td>8.822712</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>10.773194</td>\n",
       "      <td>12.778286</td>\n",
       "      <td>11.652669</td>\n",
       "      <td>8.970365</td>\n",
       "      <td>7.637110</td>\n",
       "      <td>8.529339</td>\n",
       "      <td>9.320190</td>\n",
       "      <td>6.831780</td>\n",
       "      <td>0.592656</td>\n",
       "      <td>-6.088131</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.446031</td>\n",
       "      <td>0.694977</td>\n",
       "      <td>1.714937</td>\n",
       "      <td>2.762491</td>\n",
       "      <td>3.859814</td>\n",
       "      <td>4.930628</td>\n",
       "      <td>5.979158</td>\n",
       "      <td>7.117027</td>\n",
       "      <td>8.307706</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>-11.673164</td>\n",
       "      <td>-9.803854</td>\n",
       "      <td>-7.338249</td>\n",
       "      <td>-5.520587</td>\n",
       "      <td>-3.916504</td>\n",
       "      <td>-1.764414</td>\n",
       "      <td>0.401452</td>\n",
       "      <td>0.814396</td>\n",
       "      <td>-1.765881</td>\n",
       "      <td>-6.511787</td>\n",
       "      <td>...</td>\n",
       "      <td>15.167360</td>\n",
       "      <td>13.969464</td>\n",
       "      <td>12.170960</td>\n",
       "      <td>10.332232</td>\n",
       "      <td>8.886376</td>\n",
       "      <td>8.105309</td>\n",
       "      <td>7.956192</td>\n",
       "      <td>7.909022</td>\n",
       "      <td>7.063335</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>26.508423</td>\n",
       "      <td>29.570061</td>\n",
       "      <td>30.927824</td>\n",
       "      <td>29.329739</td>\n",
       "      <td>25.063768</td>\n",
       "      <td>19.500076</td>\n",
       "      <td>14.430696</td>\n",
       "      <td>11.417859</td>\n",
       "      <td>11.171830</td>\n",
       "      <td>13.123591</td>\n",
       "      <td>...</td>\n",
       "      <td>3.124659</td>\n",
       "      <td>2.387371</td>\n",
       "      <td>1.217971</td>\n",
       "      <td>0.343328</td>\n",
       "      <td>-0.034028</td>\n",
       "      <td>-0.270347</td>\n",
       "      <td>-0.687760</td>\n",
       "      <td>-1.110718</td>\n",
       "      <td>-1.096807</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>0.400945</td>\n",
       "      <td>1.867782</td>\n",
       "      <td>2.782614</td>\n",
       "      <td>3.434025</td>\n",
       "      <td>4.428894</td>\n",
       "      <td>5.875165</td>\n",
       "      <td>7.232728</td>\n",
       "      <td>7.917486</td>\n",
       "      <td>7.944464</td>\n",
       "      <td>7.848987</td>\n",
       "      <td>...</td>\n",
       "      <td>-69.474396</td>\n",
       "      <td>-64.398170</td>\n",
       "      <td>-42.660366</td>\n",
       "      <td>-20.246111</td>\n",
       "      <td>-13.510144</td>\n",
       "      <td>-26.954048</td>\n",
       "      <td>-50.413074</td>\n",
       "      <td>-67.154030</td>\n",
       "      <td>-66.170212</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 31745 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0     3.645161   1.577007  -2.884674  -7.294243  -8.769628  -6.107172   \n",
       "1    -1.225078   2.687866   3.478920  -0.998662  -7.863265 -11.353711   \n",
       "2     8.414157   2.379914  -3.338521  -7.477322  -9.546935  -9.531569   \n",
       "3     3.311837   2.850084   1.313545   0.674265   1.052333   0.343137   \n",
       "4    -9.322539  -2.384815   3.101957   4.720293   3.202580   2.139584   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "355 -10.650115  -9.326292  -9.187932  -9.651434  -9.201318  -6.872770   \n",
       "356  10.773194  12.778286  11.652669   8.970365   7.637110   8.529339   \n",
       "357 -11.673164  -9.803854  -7.338249  -5.520587  -3.916504  -1.764414   \n",
       "358  26.508423  29.570061  30.927824  29.329739  25.063768  19.500076   \n",
       "359   0.400945   1.867782   2.782614   3.434025   4.428894   5.875165   \n",
       "\n",
       "     feature_6  feature_7  feature_8  feature_9  ...  feature_31735  \\\n",
       "0    -0.875113   3.444995   3.762372  -0.507442  ...      14.552163   \n",
       "1    -7.627178   2.002784  12.165368  17.727137  ...       6.335400   \n",
       "2    -7.968606  -6.104305  -5.469647  -6.837555  ...     -13.434300   \n",
       "3    -3.497101  -9.780030 -14.930172 -15.362961  ...      -7.649138   \n",
       "4     4.917171  11.307302  16.890072  16.279924  ...     -16.844177   \n",
       "..         ...        ...        ...        ...  ...            ...   \n",
       "355  -3.324494  -0.485164  -0.027376  -1.959681  ...      -8.496918   \n",
       "356   9.320190   6.831780   0.592656  -6.088131  ...      -0.446031   \n",
       "357   0.401452   0.814396  -1.765881  -6.511787  ...      15.167360   \n",
       "358  14.430696  11.417859  11.171830  13.123591  ...       3.124659   \n",
       "359   7.232728   7.917486   7.944464   7.848987  ...     -69.474396   \n",
       "\n",
       "     feature_31736  feature_31737  feature_31738  feature_31739  \\\n",
       "0        21.187590      25.256897      22.113747      13.521024   \n",
       "1        12.920719      12.482493       4.597783      -7.552145   \n",
       "2        -7.721217       2.970876       9.848282       6.062175   \n",
       "3        -3.250118       4.343658      10.612925      10.251337   \n",
       "4       -21.338095     -21.321344     -19.264174     -17.024244   \n",
       "..             ...            ...            ...            ...   \n",
       "355      -7.160340      -5.629473      -3.690045      -1.307681   \n",
       "356       0.694977       1.714937       2.762491       3.859814   \n",
       "357      13.969464      12.170960      10.332232       8.886376   \n",
       "358       2.387371       1.217971       0.343328      -0.034028   \n",
       "359     -64.398170     -42.660366     -20.246111     -13.510144   \n",
       "\n",
       "     feature_31740  feature_31741  feature_31742  feature_31743  label  \n",
       "0         6.434617       6.510839      12.609276      17.854654      0  \n",
       "1       -19.150581     -26.119247     -26.754780     -22.282345      0  \n",
       "2        -6.689582     -18.814631     -20.730404     -11.228072      0  \n",
       "3         2.091847      -8.952351     -15.475546     -13.764502      0  \n",
       "4       -14.048934      -8.670050      -1.055577       5.491176      0  \n",
       "..             ...            ...            ...            ...    ...  \n",
       "355       1.285857       3.856766       6.362743       8.822712      1  \n",
       "356       4.930628       5.979158       7.117027       8.307706      1  \n",
       "357       8.105309       7.956192       7.909022       7.063335      1  \n",
       "358      -0.270347      -0.687760      -1.110718      -1.096807      1  \n",
       "359     -26.954048     -50.413074     -67.154030     -66.170212      1  \n",
       "\n",
       "[360 rows x 31745 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c7e5a4",
   "metadata": {},
   "source": [
    "# Logistic Regression Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "45b93b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Define forward propagation function\n",
    "def forward_propagation(X, w):\n",
    "    z = np.dot(X, w)\n",
    "    y_pred = sigmoid(z)\n",
    "    return y_pred\n",
    "\n",
    "# Define gradient calculation function\n",
    "def calculate_gradient(X, y, y_pred):\n",
    "    gradient = np.dot(X.T, (y_pred - y)) / len(y)\n",
    "    return gradient\n",
    "\n",
    "# Define logistic regression function\n",
    "def logistic_regression(X, y, lr=0.01, n_iterations=1000):\n",
    "    w = np.zeros(X.shape[1])\n",
    "    for i in range(n_iterations):\n",
    "        y_pred = forward_propagation(X, w)\n",
    "        gradient = calculate_gradient(X, y, y_pred)\n",
    "        w -= lr * gradient\n",
    "    return w\n",
    "\n",
    "# Define function to evaluate model accuracy\n",
    "def evaluate_model(X, y, w):\n",
    "    y_pred = forward_propagation(X, w)\n",
    "    y_pred_binary = np.round(y_pred)\n",
    "    accuracy = np.mean(y_pred_binary == y)\n",
    "    return accuracy\n",
    "\n",
    "# Define function to perform cross-validation\n",
    "def cross_validation(X, y, n_folds=5, lr=0.01, n_iterations=1000):\n",
    "    kf = KFold(n_splits=n_folds)\n",
    "    accuracies = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        w = logistic_regression(X_train, y_train, lr=lr, n_iterations=n_iterations)\n",
    "        accuracy = evaluate_model(X_test, y_test, w)\n",
    "        accuracies.append(accuracy)\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    return mean_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2621dc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cv/mtf0qnws2jvbfff1vk2xrhpr0000gn/T/ipykernel_719/264808754.py:7: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.4694\n"
     ]
    }
   ],
   "source": [
    "# perform cross-validation\n",
    "mean_accuracy = cross_validation(X, y)\n",
    "\n",
    "print(f'Mean accuracy: {mean_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031368ab",
   "metadata": {},
   "source": [
    "# CNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "76fbc190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Initialize KFold cross-validation with 5 splits, shuffling, and random state 42\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Split data into 5 folds using KFold cross-validation\n",
    "folds = list(kf.split(X, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "71c1fa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules from Keras library\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D\n",
    "\n",
    "# Define function to create a Convolutional Neural Network (CNN) model\n",
    "def create_model():\n",
    "    # Initialize the CNN model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add 1D convolution layer with 32 filters, kernel size of 3, ReLU activation, and input shape of (31744, 1)\n",
    "    model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(31744, 1)))\n",
    "    \n",
    "    # Add max pooling layer with pool size of 2\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    # Add 1D convolution layer with 64 filters, kernel size of 3, ReLU activation\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    \n",
    "    # Add max pooling layer with pool size of 2\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    # Add 1D convolution layer with 128 filters, kernel size of 3, ReLU activation\n",
    "    model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "    \n",
    "    # Add max pooling layer with pool size of 2\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    # Flatten the output of the previous layer to a 1D vector\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Add dense layer with 64 units and ReLU activation\n",
    "    model.add(Dense(units=64, activation='relu'))\n",
    "    \n",
    "    # Add dropout layer with a rate of 0.5\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    # Add dense layer with 1 unit and sigmoid activation for binary classification\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model with Adam optimizer, binary cross-entropy loss, and accuracy metric\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Return the compiled model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7ddc09c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cv/mtf0qnws2jvbfff1vk2xrhpr0000gn/T/ipykernel_719/3697346115.py:17: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb4b9ea7dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 2s 471ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cv/mtf0qnws2jvbfff1vk2xrhpr0000gn/T/ipykernel_719/3697346115.py:17: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 457ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cv/mtf0qnws2jvbfff1vk2xrhpr0000gn/T/ipykernel_719/3697346115.py:17: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 450ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cv/mtf0qnws2jvbfff1vk2xrhpr0000gn/T/ipykernel_719/3697346115.py:17: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 444ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cv/mtf0qnws2jvbfff1vk2xrhpr0000gn/T/ipykernel_719/3697346115.py:17: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 495ms/step\n",
      "The mean accuracy is  0.85\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "results = []\n",
    "\n",
    "# loop through each fold\n",
    "for train_idx, val_idx in folds:\n",
    "    # split the data into training and validation sets\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_val, y_val = X[val_idx], y[val_idx]\n",
    "    \n",
    "    # add a dimension to the data for the Conv1D layer\n",
    "    X_train = np.expand_dims(X_train, axis=2)\n",
    "    X_val = np.expand_dims(X_val, axis=2)\n",
    "    \n",
    "    # create the Keras model with given parameters\n",
    "    model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=0)\n",
    "    \n",
    "    # train the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # make predictions on the validation data\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # compute accuracy score for the validation data\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    \n",
    "    # append the accuracy score to results list\n",
    "    results.append(acc)\n",
    "\n",
    "# compute the mean of all the accuracy scores\n",
    "print(\"The mean accuracy is \", np.mean(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9f05e5",
   "metadata": {},
   "source": [
    "# Parameter Tuning Of CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "09716fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cv/mtf0qnws2jvbfff1vk2xrhpr0000gn/T/ipykernel_719/1245486394.py:61: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb4237a23a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb3f238e5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Best: 0.936111 using {'dropout_rate': 0.5, 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize KFold cross-validation with 5 splits, shuffling, and random state 42\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Split data into 5 folds using KFold cross-validation\n",
    "folds = list(kf.split(X, y))\n",
    "\n",
    "# Define function to create a Convolutional Neural Network (CNN) model\n",
    "def create_model(dropout_rate=0.5, optimizer='adam'):\n",
    "    # Initialize the CNN model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add 1D convolution layer with 32 filters, kernel size of 3, ReLU activation, and input shape of (31744, 1)\n",
    "    model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(31744, 1)))\n",
    "\n",
    "    # Add max pooling layer with pool size of 2\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "    # Add 1D convolution layer with 64 filters, kernel size of 3, ReLU activation\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "\n",
    "    # Add max pooling layer with pool size of 2\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "    # Add 1D convolution layer with 128 filters, kernel size of 3, ReLU activation\n",
    "    model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "\n",
    "    # Add max pooling layer with pool size of 2\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "    # Flatten the output of the previous layer to a 1D vector\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Add dense layer with 64 units and ReLU activation\n",
    "    model.add(Dense(units=64, activation='relu'))\n",
    "\n",
    "    # Add dropout layer with a rate of dropout_rate\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Add dense layer with 1 unit and sigmoid activation for binary classification\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model with given optimizer, binary cross-entropy loss, and accuracy metric\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Return the compiled model\n",
    "    return model\n",
    "\n",
    "# Set the hyperparameters to tune using grid search\n",
    "param_grid = {\n",
    "    'dropout_rate': [0.25, 0.5, 0.75],\n",
    "    'optimizer': ['adam', 'sgd']\n",
    "}\n",
    "\n",
    "# Create the Keras model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=folds, verbose=1)\n",
    "\n",
    "# Fit the grid search object to the data\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "# Print the best hyperparameters and mean accuracy score\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b446e88e",
   "metadata": {},
   "source": [
    "# NOTES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "07f19c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The initial accuracy of the logistic regression model was 47%, \n",
    "#while the CNN model yielded a much higher accuracy \n",
    "#of 85%. After tuning the hyperparameters of the CNN model using grid search, \n",
    "#the accuracy of the CNN model increased even further to 93%.\n",
    "#This significant improvement in accuracy demonstrates the power of CNNs in modeling complex\n",
    "#relationships in data with multiple features. By tuning the hyperparameters of the CNN model using grid search, I was\n",
    "#able to fine-tune the model and achieve better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bb0138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
